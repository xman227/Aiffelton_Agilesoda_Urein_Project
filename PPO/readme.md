## PPO 모델 설계
- [참조](https://github.com/nikhilbarhate99/PPO-PyTorch)
- 환경에 맞춰서 구동하는데 초점을 주고 만들었습니다.
- 아직 어떤 오류 혹은 훈련이 안되는 상황이 있을지 불확실 하기 때문에 40000번의 훈련 이후 모델을 좀 더 최적화 혹은 수정할 예정입니다.
- 멘토님들의 피드백중 현재 환경에서는 GPU 연산이 적을 것이라는 얘기를 들어서 일단 GPU 없이 설계했습니다.
---
### 0525
- 설정을 잘못한게 이유일 수도 있지만 다른 모델보다 엄청나게 훈련 속도가 빠르다.
- 평균 보상이 점차 늘어나는 모습을 가시적으로 볼 수 있어서 아직까진 문제 없다 느껴진다.
