{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0281ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고\n",
    "# https://choiseokwon.tistory.com/210\n",
    "\n",
    "# Time Complexity는 H에 따라 다르다.\n",
    "# O(b^d), where d = depth, b = 각 노드의 하위 요소 수\n",
    "# heapque를 이용하면 길을 출력할 때 reverse를 안해도 됨\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, parent=None, position=None):\n",
    "        self.parent = parent\n",
    "        self.position = position\n",
    "\n",
    "        self.g = 0\n",
    "        self.h = 0\n",
    "        self.f = 0\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.position == other.position\n",
    "\n",
    "def heuristic(node, goal, D=1, D2=2 ** 0.5):  # Diagonal Distance\n",
    "    dx = abs(node.position[0] - goal.position[0])\n",
    "    dy = abs(node.position[1] - goal.position[1])\n",
    "    return D * (dx + dy) + (D2 - 2 * D) * min(dx, dy)\n",
    "\n",
    "\n",
    "def aStar(maze, start, end):\n",
    "    # startNode와 endNode 초기화\n",
    "    startNode = Node(None, start)\n",
    "    endNode = Node(None, end)\n",
    "\n",
    "    # openList, closedList 초기화\n",
    "    openList = []\n",
    "    closedList = []\n",
    "    \n",
    "    search_loc = []\n",
    "    # openList에 시작 노드 추가\n",
    "    openList.append(startNode)\n",
    "\n",
    "    # endNode를 찾을 때까지 실행\n",
    "    while openList:\n",
    "\n",
    "        # 현재 노드 지정\n",
    "        currentNode = openList[0]\n",
    "        currentIdx = 0\n",
    "\n",
    "        # 이미 같은 노드가 openList에 있고, f 값이 더 크면\n",
    "        # currentNode를 openList안에 있는 값으로 교체\n",
    "        for index, item in enumerate(openList):\n",
    "            if item.f < currentNode.f:\n",
    "                currentNode = item\n",
    "                currentIdx = index\n",
    "\n",
    "        # openList에서 제거하고 closedList에 추가\n",
    "        openList.pop(currentIdx)\n",
    "        closedList.append(currentNode)\n",
    "\n",
    "        # 현재 노드가 목적지면 current.position 추가하고\n",
    "        # current의 부모로 이동\n",
    "        if currentNode == endNode:\n",
    "            path = []\n",
    "            current = currentNode\n",
    "            while current is not None:\n",
    "                # maze 길을 표시하려면 주석 해제\n",
    "                # x, y = current.position\n",
    "                # maze[x][y] = 7 \n",
    "                path.append(current.position)\n",
    "                current = current.parent\n",
    "            return path[::-1], search_loc  # reverse\n",
    "\n",
    "        children = []\n",
    "        # 인접한 xy좌표 전부\n",
    "        for newPosition in [(0, -1), (0, 1), (-1, 0), (1, 0)]:\n",
    "\n",
    "            # 노드 위치 업데이트\n",
    "            nodePosition = (\n",
    "                currentNode.position[0] + newPosition[0],  # X\n",
    "                currentNode.position[1] + newPosition[1])  # Y\n",
    "                \n",
    "            # 미로 maze index 범위 안에 있어야함\n",
    "            within_range_criteria = [\n",
    "                nodePosition[0] > (len(maze) - 1),\n",
    "                nodePosition[0] < 0,\n",
    "                nodePosition[1] > (len(maze[len(maze) - 1]) - 1),\n",
    "                nodePosition[1] < 0,\n",
    "            ]\n",
    "\n",
    "            if any(within_range_criteria):  # 하나라도 true면 범위 밖임\n",
    "                continue\n",
    "\n",
    "            # 장애물이 있으면 다른 위치 불러오기\n",
    "            if maze[nodePosition[0]][nodePosition[1]] == 0 or maze[nodePosition[0]][nodePosition[1]] == 100:\n",
    "                continue\n",
    "\n",
    "            new_node = Node(currentNode, nodePosition)\n",
    "            children.append(new_node)\n",
    "\n",
    "        # 자식들 모두 loop\n",
    "        for child in children:\n",
    "\n",
    "            # 자식이 closedList에 있으면 continue\n",
    "            if child in closedList:\n",
    "                continue\n",
    "\n",
    "            # f, g, h값 업데이트\n",
    "            child.g = currentNode.g + 1\n",
    "            child.h = ((child.position[0] - endNode.position[0]) **\n",
    "                       2) + ((child.position[1] - endNode.position[1]) ** 2)\n",
    "            # child.h = heuristic(child, endNode) 다른 휴리스틱\n",
    "            # print(\"position:\", child.position) 거리 추정 값 보기\n",
    "            # print(\"from child to goal:\", child.h)\n",
    "            \n",
    "            child.f = child.g + child.h\n",
    "\n",
    "            # 자식이 openList에 있으고, g값이 더 크면 continue\n",
    "            if len([openNode for openNode in openList\n",
    "                    if child == openNode and child.g > openNode.g]) > 0:\n",
    "                continue\n",
    "            \n",
    "            #print(child.position)\n",
    "            search_loc.append(child.position)\n",
    "            openList.append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624ea860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.1 -1 10\n"
     ]
    }
   ],
   "source": [
    "from string import ascii_uppercase\n",
    "from astar_draw_utils import *\n",
    "from pyglet.gl import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# reward\n",
    "move_reward = 0.1\n",
    "obs_reward = -1\n",
    "goal_reward = 10\n",
    "print('reward:' , move_reward, obs_reward, goal_reward)\n",
    "\n",
    "local_path = os.path.abspath(os.path.join(os.path.dirname('__file__')))\n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        height : 그리드 높이\n",
    "        width : 그리드 너비 \n",
    "        inds : A ~ Q alphabet list\n",
    "        '''\n",
    "        # Load train data\n",
    "        self.files = pd.read_csv(os.path.join(local_path, \"./data/factory_order_test.csv\"))\n",
    "        self.height = 10\n",
    "        self.width = 9\n",
    "        self.inds = list(ascii_uppercase)[:17]\n",
    "        \n",
    "        self.total_a = 0\n",
    "        \n",
    "    def set_box(self):\n",
    "        '''\n",
    "        아이템들이 있을 위치를 미리 정해놓고 그 위치 좌표들에 아이템이 들어올 수 있으므로 그리드에 100으로 표시한다.\n",
    "        데이터 파일에서 이번 에피소드 아이템 정보를 받아 가져와야 할 아이템이 있는 좌표만 -100으로 표시한다.\n",
    "        self.local_target에 에이전트가 이번에 방문해야할 좌표들을 저장한다.\n",
    "        따라서 가져와야하는 아이템 좌표와 end point 좌표(처음 시작했던 좌표로 돌아와야하므로)가 들어가게 된다.\n",
    "        '''\n",
    "        box_data = pd.read_csv(os.path.join(local_path, \"./data/box.csv\"))\n",
    "\n",
    "        # 물건이 들어있을 수 있는 경우\n",
    "        for box in box_data.itertuples(index = True, name ='Pandas'):\n",
    "            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = 100\n",
    "\n",
    "        # 물건이 실제 들어있는 경우\n",
    "        order_item = list(set(self.inds) & set(self.items))\n",
    "        order_csv = box_data[box_data['item'].isin(order_item)]\n",
    "\n",
    "        for order_box in order_csv.itertuples(index = True, name ='Pandas'):\n",
    "            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = -100\n",
    "            # local target에 가야 할 위치 좌표 넣기\n",
    "            self.local_target.append(\n",
    "                [getattr(order_box, \"row\"),\n",
    "                 getattr(order_box, \"col\")]\n",
    "                )\n",
    "            self.item_list.append(\n",
    "                [getattr(order_box, \"row\"),\n",
    "                 getattr(order_box, \"col\")]\n",
    "            )\n",
    "            \n",
    "        #self.local_target.sort()\n",
    "        self.local_target.append([9,4]) \n",
    "        # 알파벳을 Grid에 넣어서 -> grid에 2Dconv 적용 가능\n",
    "\n",
    "    def set_obstacle(self):\n",
    "        '''\n",
    "        장애물이 있어야하는 위치는 미리 obstacles.csv에 정의되어 있다. 이 좌표들을 0으로 표시한다.\n",
    "        '''\n",
    "        obstacles_data = pd.read_csv(os.path.join(local_path, \"./data/obstacles.csv\"))\n",
    "        for obstacle in obstacles_data.itertuples(index = True, name ='Pandas'):\n",
    "            self.grid[getattr(obstacle, \"row\")][getattr(obstacle, \"col\")] = 0\n",
    "\n",
    "    def search_append(self, search):\n",
    "        for i in search:\n",
    "            #print(search)\n",
    "            self.search_loc.append(i)\n",
    "        \n",
    "    def reset(self, epi):\n",
    "        '''\n",
    "        reset()은 첫 스텝에서 사용되며 그리드에서 에이전트 위치가 start point에 있게 한다.\n",
    "\n",
    "        :param epi: episode, 에피소드 마다 가져와야 할 아이템 리스트를 불러올 때 사용\n",
    "        :return: 초기셋팅 된 그리드\n",
    "        :rtype: numpy.ndarray\n",
    "        _____________________________________________________________________________________\n",
    "        items : 이번 에피소드에서 가져와야하는 아이템들\n",
    "        terminal_location : 현재 에이전트가 찾아가야하는 목적지\n",
    "        local_target : 한 에피소드에서 찾아가야하는 아이템 좌표, 마지막 엔드 포인트 등의 위치좌표들\n",
    "        actions: visualization을 위해 에이전트 action을 저장하는 리스트\n",
    "        curloc : 현재 위치\n",
    "        '''\n",
    "        self.item_list = []\n",
    "        # initial episode parameter setting\n",
    "        self.epi = epi\n",
    "        self.items = list(self.files.iloc[self.epi])[0]\n",
    "        self.cumulative_reward = 0\n",
    "        self.terminal_location = None\n",
    "        self.local_target = []\n",
    "        self.actions = []\n",
    "        self.search_loc = []\n",
    "\n",
    "        # initial grid setting\n",
    "        self.grid = np.ones((self.height, self.width), dtype=\"float16\")\n",
    "\n",
    "        # set information about the gridworld\n",
    "        self.set_box()\n",
    "        self.set_obstacle()\n",
    "\n",
    "        # start point를 grid에 표시\n",
    "        self.curloc = [9, 4]\n",
    "        self.grid[int(self.curloc[0])][int(self.curloc[1])] = -5\n",
    "        \n",
    "        self.done = False\n",
    "        \n",
    "        return self.grid, self.local_target\n",
    "\n",
    "    def apply_action(self, action, cur_x, cur_y):\n",
    "        '''\n",
    "        에이전트가 행한 action대로 현 에이전트의 위치좌표를 바꾼다.\n",
    "        action은 discrete하며 4가지 up,down,left,right으로 정의된다.\n",
    "        \n",
    "        :param x: 에이전트의 현재 x 좌표\n",
    "        :param y: 에이전트의 현재 y 좌표\n",
    "        :return: action에 따라 변한 에이전트의 x 좌표, y 좌표\n",
    "        :rtype: int, int\n",
    "        '''\n",
    "        new_x = cur_x\n",
    "        new_y = cur_y\n",
    "        # up\n",
    "        if action == 0:\n",
    "            new_x = cur_x - 1\n",
    "        # down\n",
    "        elif action == 1:\n",
    "            new_x = cur_x + 1\n",
    "        # left\n",
    "        elif action == 2:\n",
    "            new_y = cur_y - 1\n",
    "        # right\n",
    "        else:\n",
    "            new_y = cur_y + 1\n",
    "\n",
    "        return int(new_x), int(new_y)\n",
    "\n",
    "\n",
    "    def get_reward(self, new_x, new_y, out_of_boundary):\n",
    "        '''\n",
    "        get_reward함수는 리워드를 계산하는 함수이며, 상황에 따라 에이전트가 action을 옳게 했는지 판단하는 지표가 된다.\n",
    "\n",
    "        :param new_x: action에 따른 에이전트 새로운 위치좌표 x\n",
    "        :param new_y: action에 따른 에이전트 새로운 위치좌표 y\n",
    "        :param out_of_boundary: 에이전트 위치가 그리드 밖이 되지 않도록 제한\n",
    "        :return: action에 따른 리워드\n",
    "        :rtype: float\n",
    "        '''\n",
    "\n",
    "        # 바깥으로 나가는 경우\n",
    "        if any(out_of_boundary):\n",
    "            reward = obs_reward\n",
    "                       \n",
    "        else:\n",
    "            # 장애물에 부딪히는 경우 \n",
    "            if self.grid[new_x][new_y] == 0:\n",
    "                reward = obs_reward  \n",
    "\n",
    "            # 현재 목표에 도달한 경우\n",
    "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n",
    "                reward = goal_reward\n",
    "\n",
    "            # 그냥 움직이는 경우 \n",
    "            else:\n",
    "                reward = move_reward\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        ''' \n",
    "        에이전트의 action에 따라 step을 진행한다.\n",
    "        action에 따라 에이전트 위치를 변환하고, action에 대해 리워드를 받고, 어느 상황에 에피소드가 종료되어야 하는지 등을 판단한다.\n",
    "        에이전트가 endpoint에 도착하면 gif로 에피소드에서 에이전트의 행동이 저장된다.\n",
    "\n",
    "        :param action: 에이전트 행동\n",
    "        :return:\n",
    "            grid, 그리드\n",
    "            reward, 리워드\n",
    "            cumulative_reward, 누적 리워드\n",
    "            done, 종료 여부\n",
    "            goal_ob_reward, goal까지 아이템을 모두 가지고 돌아오는 finish율 계산을 위한 파라미터\n",
    "\n",
    "        :rtype: numpy.ndarray, float, float, bool, bool/str\n",
    "\n",
    "        (Hint : 시작 위치 (9,4)에서 up말고 다른 action은 전부 장애물이므로 action을 고정하는 것이 좋음)\n",
    "        '''\n",
    "\n",
    "        self.terminal_location = self.local_target[0]\n",
    "        cur_x,cur_y = self.curloc\n",
    "        self.actions.append((cur_x, cur_y))\n",
    "\n",
    "        goal_ob_reward = False\n",
    "        \n",
    "        new_x, new_y = self.apply_action(action, cur_x, cur_y)\n",
    "\n",
    "        out_of_boundary = [new_x < 0, new_x >= self.height, new_y < 0, new_y >= self.width]\n",
    "        \n",
    "        \n",
    "        # 바깥으로 나가는 경우 종료\n",
    "        if any(out_of_boundary):\n",
    "            self.done = True\n",
    "            goal_ob_reward = True\n",
    "        else:\n",
    "            # 장애물에 부딪히는 경우 종료\n",
    "            if self.grid[new_x][new_y] == 0:\n",
    "                self.done = True\n",
    "                goal_ob_reward = True\n",
    "\n",
    "            # 현재 목표에 도달한 경우, 다음 목표설정\n",
    "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n",
    "\n",
    "                # end point 일 때\n",
    "                if [new_x, new_y] == [9,4]:\n",
    "                    self.done = True\n",
    "\n",
    "                self.local_target.remove(self.local_target[0])\n",
    "                self.grid[cur_x][cur_y] = 1\n",
    "                self.grid[new_x][new_y] = -5\n",
    "                goal_ob_reward = True\n",
    "                self.curloc = [new_x, new_y]\n",
    "            else:\n",
    "                # 그냥 움직이는 경우 \n",
    "                self.grid[cur_x][cur_y] = 1\n",
    "                self.grid[new_x][new_y] = -5\n",
    "                self.curloc = [new_x,new_y]\n",
    "                \n",
    "        reward = self.get_reward(new_x, new_y, out_of_boundary)\n",
    "        self.cumulative_reward += reward\n",
    "\n",
    "        if self.done == True:\n",
    "            if [new_x, new_y] == [9, 4]:\n",
    "                if self.terminal_location == [9, 4]:\n",
    "                    # 완료되면 GIFS 저장\n",
    "\n",
    "                    self.total_a += len(self.actions)\n",
    "                    self.total_a += len(self.search_loc)\n",
    "                    goal_ob_reward = 'finish'\n",
    "                    height = 10\n",
    "                    width = 9 \n",
    "                    display = Display(visible=False, size=(width, height))\n",
    "                    display.start()\n",
    "\n",
    "                    start_point = (9, 4)\n",
    "                    unit = 50\n",
    "                    screen_height = height * unit\n",
    "                    screen_width = width * unit\n",
    "                    log_path = \"./astar_logs\"\n",
    "                    data_path = \"./data\"\n",
    "                    #print(self.item_list)\n",
    "                    render_cls = Render(screen_width, screen_height, unit, start_point, data_path, log_path, self.item_list)\n",
    "                    \n",
    "                    for idx, new_pos in enumerate(self.search_loc ):\n",
    "                        render_cls.update_movement(new_pos, idx+1, 'search')\n",
    "                    \n",
    "                    for idx, new_pos in enumerate(self.actions ):\n",
    "                        #print(idx, new_pos[0], new_pos[1])\n",
    "                        render_cls.update_movement(new_pos, idx+1, 'action')\n",
    "                    \n",
    "                    render_cls.save_gif(self.epi)\n",
    "                    render_cls.viewer.close()\n",
    "                    display.stop()\n",
    "        \n",
    "        return self.grid, reward, self.cumulative_reward, self.done, goal_ob_reward\n",
    "    \n",
    "    def ac(self):\n",
    "        print(self.total_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe2f09d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1226/1226 [00:06<00:00, 176.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226개의 Episode 총 탐색 및 Action 시행 수\n",
      "147506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "'''\n",
    "A*_Agent\n",
    "아이템 리스트를 토대로 A* algorithm 최단거리를 탐색 후 시행한다.\n",
    "\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sim = Simulator()\n",
    "    files = pd.read_csv(\"./data/factory_order_test.csv\")\n",
    "       \n",
    "    for epi in tqdm(range(len(files))): # len(files)):\n",
    "        items = list(files.iloc[epi])[0]\n",
    "        done = False\n",
    "        i = -1\n",
    "        # reset 메서드에 local_target을 추가적으로 리턴하게 수정했음@\n",
    "        # local_target을 받아와서 출발지,목적지 좌표를 설정하기위함\n",
    "        \n",
    "        obs, local_target = sim.reset(epi)\n",
    "        actions = []\n",
    "        \n",
    "        for k in range(len(local_target)):\n",
    "            if k == 0:\n",
    "                # local_target에는 출발지 좌표는 안들어있어서 시작할때만 따로 설정\n",
    "                start = (9,4)\n",
    "            else:\n",
    "                start = local_target[k-1]\n",
    "            # 튜플로 안주고 리스트로 주면 path값이 None이 되서 에러나는데 이유는 모르겠다@@@\n",
    "            end = tuple(local_target[k])\n",
    "            \n",
    "            path, search = aStar(obs, start, end)\n",
    "\n",
    "            sim.search_append(search)\n",
    "\n",
    "            # path에는 어떻게 움직이는지 좌표값으로 들어가있다.\n",
    "            # 좌표값을 액션값으로 바꿔주기 위해 아래 작성.\n",
    "            for j in range(len(path)-1):\n",
    "                action = [path[j+1][0]-path[j][0],path[j+1][1]-path[j][1]]\n",
    "                if action == [1,0]:\n",
    "                    actions.append(1)\n",
    "                elif action == [-1,0]:\n",
    "                    actions.append(0)\n",
    "                elif action == [0,1]:\n",
    "                    actions.append(3)\n",
    "                else:\n",
    "                    actions.append(2)\n",
    "                    \n",
    "        while done == False:\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            next_obs, reward, cumul ,done, goal_reward = sim.step(actions[i])\n",
    "            \n",
    "            obs = next_obs\n",
    "            if (done == True) or (i == (len(actions)-1)):\n",
    "                i = 0\n",
    "    print('1226개의 Episode 총 탐색 및 Action 시행 수')\n",
    "    sim.ac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c972d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
